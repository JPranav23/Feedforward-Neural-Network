{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from load_dataset import*\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for converting image to data\n",
    "\n",
    "def convert_image_to_data(image, WIDTH, HEIGHT):\n",
    "    image_resized = Image.open(image).resize((WIDTH, HEIGHT))\n",
    "    image_array = np.array(image_resized).T\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Splitting the data into training and testing datasets\n",
    "\n",
    "def create_train_test_data(num_pix,test_size=0.2):\n",
    "    cat_files = glob.glob(\"datasets/cat*\")\n",
    "    dog_files = glob.glob(\"datasets/dog*\")\n",
    "\n",
    "    # Restrict cat and dog files here for testing\n",
    "    cat_list = [convert_image_to_data(i, num_pix, num_pix) for i in cat_files]\n",
    "    dog_list = [convert_image_to_data(i, num_pix, num_pix) for i in dog_files]\n",
    "\n",
    "    y_cat = np.zeros(len(cat_list))\n",
    "    y_dog = np.ones(len(dog_list))\n",
    "\n",
    "    X = np.concatenate([cat_list, dog_list])\n",
    "    X = np.concatenate([cat_list, dog_list])\n",
    "    y = np.concatenate([y_cat, y_dog])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the value of num_pix\n",
    "num_pix = 64\n",
    "\n",
    "# Loading Dataset\n",
    "datasets = load_dataset(\"car_dataset.hdf5\")\n",
    "\n",
    "# Training data\n",
    "x = np.array(datasets[\"train\"][\"X\"])\n",
    "y = np.array(datasets[\"train\"][\"Y\"])\n",
    "\n",
    "# Development data\n",
    "x1 = np.array(datasets[\"dev\"][\"X\"])\n",
    "y1 = np.array(datasets[\"dev\"][\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  517\n",
      "Number of testing examples:  172\n",
      "Height/Width of each image: 64\n",
      "(517, 64, 64, 3)\n",
      "(517,)\n",
      "(172, 64, 64, 3)\n",
      "(172,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of all examples\n",
    "\n",
    "print(\"Number of training examples: \", x.shape[0])\n",
    "print(\"Number of testing examples: \", x1.shape[0])\n",
    "print(\"Height/Width of each image:\", num_pix)\n",
    "print (x.shape)\n",
    "print (y.shape)\n",
    "print (x1.shape)\n",
    "print (y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_y_f shape: (1, 517)\n",
      "test_set_y_f shape: (1, 172)\n",
      "train_set_x shape: (12288, 517)\n",
      "test_set_x shape: (12288, 172)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping, Flattening and Normalizing the data\n",
    "flat_y = y.reshape(y.shape[0], -1).T\n",
    "flat_y1 = y1.reshape(y1.shape[0], -1).T\n",
    "\n",
    "train_set_yc = flat_y\n",
    "test_set_yc = flat_y1\n",
    "\n",
    "print (\"train_set_y_f shape: \" + str(flat_y.shape))\n",
    "print (\"test_set_y_f shape: \" + str(flat_y1.shape))\n",
    "\n",
    "flat_x = x.reshape(x.shape[0], -1).T\n",
    "flat_x1 = x1.reshape(x1.shape[0], -1).T\n",
    "\n",
    "print (\"train_set_x shape: \" + str(flat_x.shape))\n",
    "print (\"test_set_x shape: \" + str(flat_x1.shape))\n",
    "\n",
    "train_set_xc = flat_x/255\n",
    "test_set_xc = flat_x1/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid Function-\n",
    "\n",
    "def sigmoid(z):\n",
    "    \n",
    "    s = 1/(1+ np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization-\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "     \n",
    "    w = np.zeros(shape=(dim,1))\n",
    "    b = 0.0\n",
    "   \n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Propogation-\n",
    "\n",
    "def forward_propogation(w,b,X,Y) :\n",
    "    \n",
    "    m = X.shape[1]  \n",
    "   \n",
    "    Z= np.dot(w.T,X)+b\n",
    "    A = sigmoid(Z)     \n",
    "    cost = (-1/m) * np.sum(Y* np.log(A)+ (1- Y) * np.log(1-A))  \n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost,A,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward Propogation-\n",
    "\n",
    "def backward_propogation(w,b,X,Y) :\n",
    "    m = X.shape[1]  \n",
    "    Z= np.dot(w.T,X)+b\n",
    "    A = sigmoid(Z) \n",
    "    #A = forward_propogation(w,b,X,Y)\n",
    "    dz = A - Y\n",
    "    dw = (1/m)*np.dot(X,dz.T)\n",
    "    db = (1/m)*np.sum(dz)\n",
    "    \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    \n",
    "    return dw,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization Function-\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost= False) :\n",
    "    \n",
    "    costs = []\n",
    "    for i in range(num_iterations) :\n",
    "\n",
    "        cost,A,m = forward_propogation(w,b,X,Y)\n",
    "        dw,db = backward_propogation(w,b,X,Y)\n",
    "\n",
    "        w = w-learning_rate*dw\n",
    "        b = b-learning_rate*db\n",
    "\n",
    "        if i % 100 == 0:\n",
    "                costs.append(cost)\n",
    "\n",
    "        if print_cost and i % 100 == 0:\n",
    "                print (\"Cost after iteration %i: %f\" %(i,cost))\n",
    "\n",
    "    return dw,db,w,b,costs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Function-\n",
    "\n",
    "def predict(w, b, X_test):\n",
    "    \n",
    "    m = X_test.shape[1]\n",
    "    w = w.reshape(X_test.shape[0], 1)\n",
    "    Z= np.dot(w.T,X_test) + b\n",
    "    A = sigmoid(Z)\n",
    "    Y_prediction = np.around(A)\n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model-\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 3000, learning_rate = 0.25, print_cost = False):\n",
    "       \n",
    "    # initialize parameters with zeros \n",
    "    n = X_train.shape[0]\n",
    "    w, b = initialize_with_zeros(dim=n)\n",
    "    \n",
    "    # Gradient descent \n",
    "    dw,db,w,b,costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    # Predicting test/train set\n",
    "    Y_prediction_test = predict(w,b,X_test)\n",
    "    Y_prediction_train = predict(w,b,X_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 517)\n",
      "(1, 517)\n",
      "(12288, 173)\n",
      "(1, 173)\n"
     ]
    }
   ],
   "source": [
    "# Printing the sizes of datasets\n",
    "\n",
    "x = np.array(datasets[\"train\"][\"X\"])\n",
    "flat_x = x.reshape(x.shape[0], -1).T\n",
    "train_set_xc1 = flat_x/255\n",
    "print (train_set_xc1.shape)\n",
    "\n",
    "y = np.array(datasets[\"train\"][\"Y\"])\n",
    "flat_y = y.reshape(y.shape[0], -1).T\n",
    "train_set_yc1 = flat_y\n",
    "print (train_set_yc1.shape)\n",
    "\n",
    "x1 = np.array(datasets[\"test\"][\"X\"])\n",
    "flat_x1 = x1.reshape(x1.shape[0], -1).T\n",
    "test_set_xc1 = flat_x1/255\n",
    "print (test_set_xc1.shape)\n",
    "\n",
    "y1 = np.array(datasets[\"test\"][\"Y\"])\n",
    "flat_y1 = y1.reshape(y1.shape[0], -1).T\n",
    "test_set_yc1 = flat_y1\n",
    "print (test_set_yc1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.548509\n",
      "Cost after iteration 200: 0.496297\n",
      "Cost after iteration 300: 0.459536\n",
      "Cost after iteration 400: 0.432244\n",
      "Cost after iteration 500: 0.411066\n",
      "Cost after iteration 600: 0.394034\n",
      "Cost after iteration 700: 0.379940\n",
      "Cost after iteration 800: 0.368004\n",
      "Cost after iteration 900: 0.357705\n",
      "Cost after iteration 1000: 0.348679\n",
      "Cost after iteration 1100: 0.340667\n",
      "Cost after iteration 1200: 0.333477\n",
      "Cost after iteration 1300: 0.326965\n",
      "Cost after iteration 1400: 0.321019\n",
      "Cost after iteration 1500: 0.315553\n",
      "Cost after iteration 1600: 0.310498\n",
      "Cost after iteration 1700: 0.305796\n",
      "Cost after iteration 1800: 0.301404\n",
      "Cost after iteration 1900: 0.297283\n",
      "Cost after iteration 2000: 0.293401\n",
      "Cost after iteration 2100: 0.289732\n",
      "Cost after iteration 2200: 0.286254\n",
      "Cost after iteration 2300: 0.282948\n",
      "Cost after iteration 2400: 0.279796\n",
      "Cost after iteration 2500: 0.276785\n",
      "Cost after iteration 2600: 0.273902\n",
      "Cost after iteration 2700: 0.271136\n",
      "Cost after iteration 2800: 0.268477\n",
      "Cost after iteration 2900: 0.265917\n",
      "Cost after iteration 3000: 0.263449\n",
      "Cost after iteration 3100: 0.261066\n",
      "Cost after iteration 3200: 0.258761\n",
      "Cost after iteration 3300: 0.256529\n",
      "Cost after iteration 3400: 0.254366\n",
      "Cost after iteration 3500: 0.252267\n",
      "Cost after iteration 3600: 0.250228\n",
      "Cost after iteration 3700: 0.248245\n",
      "Cost after iteration 3800: 0.246316\n",
      "Cost after iteration 3900: 0.244436\n",
      "Cost after iteration 4000: 0.242604\n",
      "Cost after iteration 4100: 0.240816\n",
      "Cost after iteration 4200: 0.239071\n",
      "Cost after iteration 4300: 0.237366\n",
      "Cost after iteration 4400: 0.235700\n",
      "Cost after iteration 4500: 0.234070\n",
      "Cost after iteration 4600: 0.232474\n",
      "Cost after iteration 4700: 0.230912\n",
      "Cost after iteration 4800: 0.229381\n",
      "Cost after iteration 4900: 0.227881\n",
      "train accuracy: 92.06963249516441 %\n",
      "test accuracy: 87.28323699421965 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Regression Model, Cost Function and it's Plot-\n",
    "\n",
    "d = model(train_set_xc1, train_set_yc1, test_set_xc1, test_set_yc1,  num_iterations = 5000, learning_rate = 0.0005, print_cost = True)\n",
    "\n",
    "costs =np.squeeze(d['costs'])\n",
    "\n",
    "plt.plot(costs)\n",
    "plt.ylabel('Cost')\n",
    "plt.title(\"Plot\")\n",
    "plt.xlabel('Iterations (per hundred)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Importing the functions\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from testCases_v2 import *\n",
    "from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backward\n",
    "from dnn_utils_v2 import load_data\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization-\n",
    "\n",
    "def initialize_parameters_deep(layer_dims):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            \n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1])\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 0.72642933 -0.27358579 -0.23620559 -0.47984616  0.38702206]\n",
      " [-1.0292794   0.78030354 -0.34042208  0.14267862 -0.11152182]\n",
      " [ 0.65387455 -0.92132293 -0.14418936 -0.17175433  0.50703711]\n",
      " [-0.49188633 -0.07711224 -0.39259022  0.01887856  0.26064289]]\n",
      "b1 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2 = [[-0.55030959  0.57236185  0.45079536  0.25124717]\n",
      " [ 0.45042797 -0.34186393 -0.06144511 -0.46788472]\n",
      " [-0.13394404  0.26517773 -0.34583038 -0.19837676]]\n",
      "b2 = [[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# Printing the value of all parameters\n",
    "\n",
    "np.random.seed(3)\n",
    "parameters = initialize_parameters_deep([5,4,3])\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Propogation for Deep Neural Network-\n",
    "\n",
    "# import the linear_activation_forward\n",
    "from dnn_utils_v2 import linear_activation_forward\n",
    "\n",
    "def L_model_forward(X, parameters):\n",
    "    \n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  \n",
    "    \n",
    "    # Implementing [LINEAR -> RELU]*(L-1).\n",
    "    # Using a for loop to replicate [LINEAR->RELU] (L-1) times\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # This is the last layer L which uses sigmoid activation function\n",
    "    # Implementing LINEAR -> SIGMOID. .\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "    \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL = [[0.17007265 0.2524272 ]]\n",
      "Length of caches list = 2\n"
     ]
    }
   ],
   "source": [
    "X, parameters = L_model_forward_test_case()\n",
    "AL, caches = L_model_forward(X, parameters)\n",
    "print(\"AL = \" + str(AL))\n",
    "print(\"Length of caches list = \" + str(len(caches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.41493159961539694\n"
     ]
    }
   ],
   "source": [
    "# Importing cost function from the utility file\n",
    "from dnn_utils_v2 import compute_cost\n",
    "\n",
    "Y, AL = compute_cost_test_case()\n",
    "print(\"cost = \" + str(compute_cost(AL, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward Propogation for Deep Neural Network-\n",
    "\n",
    "from dnn_utils_v2 import linear_activation_backward\n",
    "\n",
    "def L_model_backward(AL, Y, caches):\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(caches) \n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) \n",
    "    \n",
    "    # Initializing the backward propagation\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1-Y, 1-AL))\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        current_cache = caches[l]\n",
    "        # using linear_activation_backward to get the derivatives\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, activation = \"relu\")\n",
    "        # saving the derivatives into a grads dictionary\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW1 = [[0.41010002 0.07807203 0.13798444 0.10502167]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.05283652 0.01005865 0.01777766 0.0135308 ]]\n",
      "db1 = [[-0.22007063]\n",
      " [ 0.        ]\n",
      " [-0.02835349]]\n",
      "dA1 = [[ 0.          0.52257901]\n",
      " [ 0.         -0.3269206 ]\n",
      " [ 0.         -0.32070404]\n",
      " [ 0.         -0.74079187]]\n"
     ]
    }
   ],
   "source": [
    "# Printing the value of dW1, db1, dA1-\n",
    "\n",
    "AL, Y_assess, caches = L_model_backward_test_case()\n",
    "grads = L_model_backward(AL, Y_assess, caches)\n",
    "print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "print (\"dA1 = \"+ str(grads[\"dA1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-0.59562069 -0.09991781 -2.14584584  1.82662008]\n",
      " [-1.76569676 -0.80627147  0.51115557 -1.18258802]\n",
      " [-1.0535704  -0.86128581  0.68284052  2.20374577]]\n",
      "b1 = [[-0.04659241]\n",
      " [-1.28888275]\n",
      " [ 0.53405496]]\n",
      "W2 = [[-0.55569196  0.0354055   1.32964895]]\n",
      "b2 = [[-0.84610769]]\n"
     ]
    }
   ],
   "source": [
    "# Printing the values of all parameters-\n",
    "\n",
    "from dnn_utils_v2 import update_parameters\n",
    "parameters, grads = update_parameters_test_case()\n",
    "parameters = update_parameters(parameters, grads, 0.1)\n",
    "\n",
    "print (\"W1 = \"+ str(parameters[\"W1\"]))\n",
    "print (\"b1 = \"+ str(parameters[\"b1\"]))\n",
    "print (\"W2 = \"+ str(parameters[\"W2\"]))\n",
    "print (\"b2 = \"+ str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural Network Model Implementation-\n",
    "\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         \n",
    "    \n",
    "    # Parameters initialization\n",
    "    parameters = initialize_parameters_deep(layer_dims)\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        # Computing cost.\n",
    "        cost = compute_cost(AL, Y)\n",
    "        \n",
    "        # Backward propagation.\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        \n",
    "        # Updating parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "                \n",
    "        # Printing the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # Ploting the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 517)\n",
      "(1, 517)\n",
      "(12288, 173)\n",
      "(1, 173)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and print their sizes\n",
    "train_x_orig = train_set_xc1 \n",
    "train_y = train_set_yc1\n",
    "test_x_orig = test_set_xc1 \n",
    "test_y = test_set_yc1 \n",
    "\n",
    "print(train_x_orig.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x_orig.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.642773\n",
      "Cost after iteration 100: 0.411428\n",
      "Cost after iteration 200: 0.327570\n",
      "Cost after iteration 300: 0.278502\n",
      "Cost after iteration 400: 0.232496\n",
      "Cost after iteration 500: 0.203679\n",
      "Cost after iteration 600: 0.280351\n",
      "Cost after iteration 700: 0.106251\n",
      "Cost after iteration 800: 0.087284\n",
      "Cost after iteration 900: 0.067336\n",
      "Cost after iteration 1000: 0.204383\n",
      "Cost after iteration 1100: 0.060864\n",
      "Cost after iteration 1200: 0.046707\n",
      "Cost after iteration 1300: 0.036495\n",
      "Cost after iteration 1400: 0.029322\n",
      "Cost after iteration 1500: 0.024356\n",
      "Cost after iteration 1600: 0.020823\n",
      "Cost after iteration 1700: 0.018232\n",
      "Cost after iteration 1800: 0.016275\n",
      "Cost after iteration 1900: 0.014755\n",
      "Cost after iteration 2000: 0.013553\n",
      "Cost after iteration 2100: 0.012586\n",
      "Cost after iteration 2200: 0.011792\n",
      "Cost after iteration 2300: 0.011131\n",
      "Cost after iteration 2400: 0.010572\n",
      "Cost after iteration 2500: 0.010095\n",
      "Cost after iteration 2600: 0.009682\n",
      "Cost after iteration 2700: 0.009321\n",
      "Cost after iteration 2800: 0.009023\n",
      "Cost after iteration 2900: 0.008762\n",
      "Cost after iteration 3000: 0.008531\n",
      "Cost after iteration 3100: 0.008325\n",
      "Cost after iteration 3200: 0.008139\n",
      "Cost after iteration 3300: 0.007972\n",
      "Cost after iteration 3400: 0.007820\n",
      "Cost after iteration 3500: 0.007681\n",
      "Cost after iteration 3600: 0.007556\n",
      "Cost after iteration 3700: 0.007441\n",
      "Cost after iteration 3800: 0.007334\n",
      "Cost after iteration 3900: 0.007236\n",
      "Cost after iteration 4000: 0.007144\n",
      "Cost after iteration 4100: 0.007059\n",
      "Cost after iteration 4200: 0.006979\n",
      "Cost after iteration 4300: 0.006904\n",
      "Cost after iteration 4400: 0.006834\n",
      "Cost after iteration 4500: 0.006767\n",
      "Cost after iteration 4600: 0.006704\n",
      "Cost after iteration 4700: 0.006645\n",
      "Cost after iteration 4800: 0.006588\n",
      "Cost after iteration 4900: 0.006534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training the model-\n",
    "\n",
    "layer_dims = [12288,15,10,7,1]\n",
    "model_parameters = L_layer_model(train_x_orig, train_y, layer_dims, num_iterations = 5000, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Function-\n",
    "\n",
    "def predict(X, parameters):\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    # Round the probabilities to get the class labels.\n",
    "    probability = probas > 0.5\n",
    "    p = probability.astype(float)\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0000000000000002\n",
      "Test Accuracy: 0.9017341040462425\n"
     ]
    }
   ],
   "source": [
    "# Predictions-\n",
    "\n",
    "predictions_train = predict(train_x_orig, model_parameters)\n",
    "m_train = train_y.shape[1]\n",
    "print(\"Train Accuracy: \"  + str(np.sum((predictions_train == train_y)/m_train)))\n",
    "m_test = test_y.shape[1]\n",
    "predictions_test = predict(test_x_orig, model_parameters)\n",
    "print(\"Test Accuracy: \"  + str(np.sum((predictions_test == test_y)/m_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results-\n",
    "\n",
    "\n",
    "# Cost for Logistic Regression after 5000 iterations and learning rate 0.0005 is 0.227881.\n",
    "# Accuracy for Logistic Regression after 5000 iterations and learning rate 0.0005 is -\n",
    "# train accuracy: 92.06963249516441 %\n",
    "# test accuracy: 87.28323699421965 %\n",
    "\n",
    "# Cost for Deep Neural Network with 3 hidden layers after 5000 iterations and learning rate 0.0075 is 0.031003.\n",
    "# Accuracy Deep Neural Network with 3 hidden layers is -\n",
    "# Train Accuracy: 99.03288201160545 %\n",
    "# Test Accuracy: 90.17341040462425 %\n",
    "\n",
    "# Hence, we can conclude that Deep Neural Network model is able to reduce the cost function to a lower value than Logistic Regression Model.\n",
    "# Also, accuracy of Deep Neural Network model on testing data is around 90 %, whereas for the Logistic Regression Model is around 87 %.\n",
    "# Hence, we can conclude that Deep Neural Network model is a better classifier than Logistic Regression classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
